{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30be40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e87e2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10\n",
    "data_number = 1000\n",
    "data_size = 784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c7c5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing and initializing the dataset and the labels\n",
    "f_labels = open('mnist_labels.txt', 'r')\n",
    "f_data = open('mnist_data.txt','r')\n",
    "\n",
    "labels = f_labels.read()\n",
    "data = f_data.read()\n",
    "\n",
    "labels = labels.split()\n",
    "data = data.split()\n",
    "holder = list(range(10000))\n",
    "for i in range(10000):\n",
    "    holder[i] = data[data_size*i:data_size*(i+1)] \n",
    "    holder[i] = [int(x) for x in holder[i]]\n",
    "data = holder\n",
    "labels = [int(x) for x in labels]\n",
    "\n",
    "f_labels.close()\n",
    "f_data.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9453f680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vector sum function for numerical lists\n",
    "def vector_sum(l1,l2):\n",
    "    summ = []\n",
    "    for i in range(len(l1)):\n",
    "        summ.append(l1[i]+l2[i])\n",
    "    return summ\n",
    "# Vector subtraction function for numerical lists\n",
    "def vector_subt(l1,l2):\n",
    "    subt = []\n",
    "    for i in range(len(l1)):\n",
    "        subt.append(l1[i]-l2[i])\n",
    "    return subt\n",
    "# Dot product function for numerical lists\n",
    "def dot_product(l1,l2):\n",
    "    mul = []\n",
    "    for i in range(len(l1)):\n",
    "        mul.append(l1[i]*l2[i])\n",
    "    dot = sum(mul)\n",
    "    return dot\n",
    "# Division of each elements in a numerical list\n",
    "def element_div(l,denom):\n",
    "    res = []\n",
    "    for i in range(len(l)):\n",
    "        res.append(l[i]/denom)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9b0ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function chooses 10 random instances from each labels as initial centroids.\n",
    "def initialize_supervised_means(k, X, number, labels):\n",
    "    means = []\n",
    "    rows = []\n",
    "    for i in range(k):\n",
    "        index = random.randint(0,number)\n",
    "        while labels[index] != i:\n",
    "            index = random.randint(0,number)\n",
    "            while index in rows:\n",
    "                index = random.randint(0,number)\n",
    "        rows.append(index)\n",
    "        means.append(X[rows[i]])\n",
    "    return means\n",
    "# A function returning the Euclidean distance between two numerical lists\n",
    "def euclidean_distance(l1,l2):\n",
    "    dist_vec = vector_subt(l1,l2)\n",
    "    return math.sqrt(dot_product(dist_vec, dist_vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bcf99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans(k, X, size, number, labels):\n",
    "    # Class values for each data initialized as 0\n",
    "    data_class = [0]*number\n",
    "    # Initializing the random means \n",
    "    means = initialize_supervised_means(k, X, number, labels)\n",
    "    err = 1\n",
    "    iteration = 0\n",
    "    # Iteration of K-means clustering. The exit condition is the convergence of all centroids.\n",
    "    while err > 0:\n",
    "        err = 0\n",
    "        means_prev = list.copy(means)\n",
    "    # Finding the minimum distance between each data and the centroids.\n",
    "        for i in range(number):\n",
    "            distances = [0]*k\n",
    "            for j in range(k):\n",
    "                distances[j] = euclidean_distance(means[j], X[i])\n",
    "            data_class[i] = distances.index(min(distances))\n",
    "    # Assigning new centroid values by averaging the elements from same cluster. \n",
    "        for i in range(k):\n",
    "            class_sum = [0]*size\n",
    "            class_element_num = 0\n",
    "            for j in range(number):\n",
    "                if data_class[j] == i:\n",
    "                    class_sum = vector_sum(class_sum, X[j])\n",
    "                    class_element_num = class_element_num + 1\n",
    "            if class_element_num != 0:\n",
    "                means[i] = element_div(class_sum, class_element_num)\n",
    "                means[i] = [int(x) for x in means[i]]\n",
    "    # Increasing the error value for each centroids changed in the iteration\n",
    "            if means[i] != means_prev[i]:\n",
    "                err = err + 1\n",
    "        iteration = iteration + 1\n",
    "        print(\"Iteration number: {}\".format(iteration))\n",
    "        print(\"Number of mean values changed: {}\".format(err))\n",
    "    return [data_class, means]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599b7b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns a legend for the predicted values by comparing them with the correct labels\n",
    "def label_finder(label_number, cluster, label):\n",
    "    legend = [0]*label_number\n",
    "    for i in range(label_number):\n",
    "        label_list = [0]*10\n",
    "        for j in range(len(cluster)):\n",
    "            if cluster[j] == i:\n",
    "                label_list[label[j]] = label_list[label[j]] + 1\n",
    "        legend[i] = label_list.index(max(label_list))\n",
    "    return legend\n",
    "# counts the number of wrong labels for each class and returns it as a list\n",
    "def calculate_wrong_labels(label_number, cluster, label):\n",
    "    label_error = []\n",
    "    for j in range(label_number):\n",
    "        num_wrong = 0\n",
    "        for i in range(len(cluster)):\n",
    "            if cluster[i] == j:\n",
    "                if cluster[i] != label[i]:\n",
    "                    num_wrong += 1\n",
    "        label_error.append(num_wrong)\n",
    "    return label_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c03d73",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "[predictions, means] = kmeans(k, data, data_size, data_number, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c90645",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "label_legend = label_finder(k, predictions, labels)\n",
    "corrected_predictions = [label_legend[predictions[x]] for x in range(len(predictions))]\n",
    "\"\"\"\n",
    "print(\"Predicted outcomes from K-means clustering:\")\n",
    "print(corrected_predictions)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e335d853",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_labels = calculate_wrong_labels(k, corrected_predictions, labels)\n",
    "print(wrong_labels)\n",
    "print(\"Total wrong answers: {}\".format(sum(wrong_labels)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
